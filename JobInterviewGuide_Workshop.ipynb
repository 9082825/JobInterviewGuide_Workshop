{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00445738",
   "metadata": {},
   "source": [
    "\n",
    "# JobInterviewGuide_Workshop — Personalized Study Guide\n",
    "\n",
    "**Focus areas (from your quiz results):**  \n",
    "1) Train/Validation/Test Split & Data Leakage  \n",
    "2) Linear Regression Residuals & Diagnostics  \n",
    "3) R-squared (R²) Interpretation  \n",
    "4) Gradient Descent & Learning Rate\n",
    "\n",
    "This notebook mirrors the tone and structure of the workshop materials: short **concept primers**, followed by **guided practice** and **Try-It** scaffolding cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85000af",
   "metadata": {},
   "source": [
    "## 1) Train / Validation / Test Split & Data Leakage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21417165",
   "metadata": {},
   "source": [
    "\n",
    "**Why it matters:**  \n",
    "We evaluate models on **unseen data** to estimate real-world performance. **Data leakage** happens when information from the test (or future) data leaks into model training or preprocessing steps, leading to **overly optimistic** metrics.\n",
    "\n",
    "**Key rules:**  \n",
    "- Split first → then fit transforms **only on training** (and apply to val/test).  \n",
    "- Keep target leakage out of features (e.g., post-outcome variables).  \n",
    "- Use a validation set (or cross-validation) for model selection; reserve the test set **once** for final evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dea1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.14.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Conestoga Projects/CSCN8010_MLF/JobInterviewGuide_Workshop/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guided Practice: Correct vs. leaky preprocessing\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Correct pipeline: scaler fit on TRAIN only, applied to val/test via Pipeline\n",
    "pipe_correct = Pipeline([('scaler', StandardScaler()), ('lr', LinearRegression())])\n",
    "pipe_correct.fit(X_train, y_train)\n",
    "r2_val_correct = pipe_correct.score(X_val, y_val)\n",
    "r2_test_correct = pipe_correct.score(X_test, y_test)\n",
    "\n",
    "# Leaky approach: scaler fit on ALL data (simulating leakage)\n",
    "scaler_leaky = StandardScaler().fit(np.vstack([X_train, X_val, X_test]))\n",
    "X_train_leaky = scaler_leaky.transform(X_train)\n",
    "X_val_leaky   = scaler_leaky.transform(X_val)\n",
    "X_test_leaky  = scaler_leaky.transform(X_test)\n",
    "\n",
    "lr_leaky = LinearRegression().fit(X_train_leaky, y_train)\n",
    "r2_val_leaky = lr_leaky.score(X_val_leaky, y_val)\n",
    "r2_test_leaky = lr_leaky.score(X_test_leaky, y_test)\n",
    "\n",
    "print(\"Correct   R² (val, test):\", round(r2_val_correct, 3), round(r2_test_correct, 3))\n",
    "print(\"**Leaky** R² (val, test):\", round(r2_val_leaky, 3), round(r2_test_leaky, 3))\n",
    "print(\"\\nNote: If 'leaky' appears much higher, that's a red flag — metrics are inflated by leakage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try-It: Replace LinearRegression with a regularized model (Ridge or Lasso) and compare again.\n",
    "# from sklearn.linear_model import Ridge\n",
    "# pipe_correct = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge(alpha=1.0))])\n",
    "# pipe_correct.fit(X_train, y_train)\n",
    "# print(\"Ridge R² (val, test):\", round(pipe_correct.score(X_val, y_val),3), round(pipe_correct.score(X_test, y_test),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee791e35",
   "metadata": {},
   "source": [
    "## 2) Linear Regression Residuals & Diagnostics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8cfb5",
   "metadata": {},
   "source": [
    "\n",
    "**Residual** = observed − predicted. Well-behaved residuals should be **centered around 0**, show **no clear pattern** vs. fitted values, and approximate **constant variance**.\n",
    "\n",
    "**Checks you should do in interviews:**  \n",
    "- Plot residuals vs. predictions (look for randomness).  \n",
    "- Plot histogram of residuals (approx. symmetric).  \n",
    "- Investigate outliers/influential points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a89f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Synthetic linear data with noise + slight heteroscedasticity\n",
    "rng = np.random.RandomState(0)\n",
    "X = np.linspace(0, 10, 200).reshape(-1,1)\n",
    "y_true = 3.0 * X.squeeze() + 5.0\n",
    "noise = rng.normal(0, 1 + 0.2*X.squeeze(), size=X.shape[0])  # variance grows with X\n",
    "y = y_true + noise\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "res = y_test - y_pred\n",
    "\n",
    "print(\"Coefficients:\", lr.coef_, \"Intercept:\", round(lr.intercept_,3))\n",
    "print(\"Test R²:\", round(lr.score(X_test, y_test), 3))\n",
    "\n",
    "# Residuals vs predictions\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, res, alpha=0.7)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual (y - ŷ)\")\n",
    "plt.title(\"Residuals vs Predicted\")\n",
    "plt.show()\n",
    "\n",
    "# Residual histogram\n",
    "plt.figure()\n",
    "plt.hist(res, bins=20)\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try-It: Create polynomial features to reduce pattern in residuals and compare.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "poly_pipe = Pipeline([('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                      ('lr', LinearRegression())])\n",
    "poly_pipe.fit(X_train, y_train)\n",
    "y_pred2 = poly_pipe.predict(X_test)\n",
    "\n",
    "import numpy as np\n",
    "res2 = y_test - y_pred2\n",
    "print(\"Poly(deg=2) Test R²:\", round(poly_pipe.score(X_test, y_test), 3))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(y_pred2, res2, alpha=0.7)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted (poly)\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residuals vs Predicted (Polynomial)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f61ee",
   "metadata": {},
   "source": [
    "## 3) R-squared (R²) Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6174c0",
   "metadata": {},
   "source": [
    "\n",
    "**R²** measures the proportion of variance in the target explained by the model.  \n",
    "\n",
    "**Interview-ready notes:**  \n",
    "- \\( R^2 = 1 - \\frac{\\sum (y-\\hat{y})^2}{\\sum (y-\\bar{y})^2} \\)  \n",
    "- High R² ≠ good model (it can be inflated by complexity).  \n",
    "- Prefer **Adjusted R²** for multiple regression to penalize unnecessary features.  \n",
    "- Always pair R² with residual diagnostics and hold-out performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dadeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Compare simple vs. overfit model on the same data\n",
    "rng = np.random.RandomState(7)\n",
    "X = np.linspace(-3, 3, 120).reshape(-1,1)\n",
    "y = 2*X.squeeze()**2 + rng.normal(0, 1.5, size=X.shape[0])  # quadratic relationship\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Linear (deg=1)\": Pipeline([('poly', PolynomialFeatures(1, include_bias=False)), ('lr', LinearRegression())]),\n",
    "    \"Moderate (deg=2)\": Pipeline([('poly', PolynomialFeatures(2, include_bias=False)), ('lr', LinearRegression())]),\n",
    "    \"High (deg=8)\": Pipeline([('poly', PolynomialFeatures(8, include_bias=False)), ('lr', LinearRegression())]),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name:>16} | R²={r2_score(y_test, y_pred):.3f}  MSE={mean_squared_error(y_test, y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try-It: Implement Adjusted R²\n",
    "# adj_R2 = 1 - (1 - R2) * (n - 1) / (n - p - 1)\n",
    "# Set n = number of samples in test, p = number of features after polynomial expansion (exclude bias).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd389036",
   "metadata": {},
   "source": [
    "## 4) Gradient Descent & Learning Rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76749ac",
   "metadata": {},
   "source": [
    "\n",
    "The **learning rate (η)** controls the **step size** when moving along the negative gradient of the loss surface.\n",
    "\n",
    "**Failure modes:**  \n",
    "- Too large → divergence or oscillation.  \n",
    "- Too small → very slow convergence.\n",
    "\n",
    "**Interview tip:** Show learning curves under different η and explain the trade-off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simple 1D quadratic loss: L(w) = (w - 3)^2\n",
    "def grad(w): \n",
    "    return 2*(w - 3)\n",
    "\n",
    "def run_gd(eta, steps=20, w0=0.0):\n",
    "    w = w0\n",
    "    traj = [(0, w, (w-3)**2)]\n",
    "    for t in range(1, steps+1):\n",
    "        w = w - eta*grad(w)\n",
    "        traj.append((t, w, (w-3)**2))\n",
    "    return traj\n",
    "\n",
    "for lr in [0.05, 0.2, 0.8, 1.2]:\n",
    "    traj = run_gd(lr, steps=10, w0=0.0)\n",
    "    final = traj[-1]\n",
    "    print(f\"eta={lr:<4} -> final w={final[1]:.4f}, loss={final[2]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try-It: Plot trajectories for two learning rates to visualize convergence behavior.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def run_vals(eta, steps=20, w0=0.0):\n",
    "    w = w0\n",
    "    ws, ls = [], []\n",
    "    for t in range(steps):\n",
    "        ws.append(w); ls.append((w-3)**2)\n",
    "        w = w - eta*2*(w - 3)\n",
    "    return np.array(ws), np.array(ls)\n",
    "\n",
    "w1, l1 = run_vals(eta=0.2, steps=30, w0=0.0)\n",
    "w2, l2 = run_vals(eta=1.2, steps=30, w0=0.0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(l1, label=\"eta=0.2\")\n",
    "plt.plot(l2, label=\"eta=1.2\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Rate vs. Convergence\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee0d60",
   "metadata": {},
   "source": [
    "## Wrap-Up & Interview Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d570e",
   "metadata": {},
   "source": [
    "\n",
    "- Explain a recent case where you **prevented data leakage**. What checks did you implement?  \n",
    "- Show a residual plot and describe whether linear model assumptions hold.  \n",
    "- Interpret an **R²** of 0.35 vs. 0.85 in context. What else would you report?  \n",
    "- Describe how you would **choose a learning rate** and detect divergence in practice.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
